{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1691925b-eb5f-409b-9a40-9f7b85ed3a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a6a41ac-a5f1-43da-b496-7997740d1f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall scipy\n",
    "# !pip install scipy==1.10.1\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a274c9a4-466d-4c18-9a27-c4a42bcb0a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy.stats import levene\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import f_oneway, kruskal\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import skew, kurtosis\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import distance\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee84e3a-1998-4da7-8071-c471e27c7c54",
   "metadata": {},
   "source": [
    "# **Loading Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e4ec75-c643-49b5-b81d-9afad71c68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_nlp = pd.read_csv('./data/non_nlp_features/df_non_nlp_feats1.csv')\n",
    "df_nlp = pd.read_csv('./data/nlp_features/df_basic_nlp_feats1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "444856ae-5ac8-489e-8850-b842b8acd2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>project_title_cln</th>\n",
       "      <th>proj_essay1_cln</th>\n",
       "      <th>proj_essay2_cln</th>\n",
       "      <th>project_resource_summary_cln</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p253737</td>\n",
       "      <td>0</td>\n",
       "      <td>educ support english learner home</td>\n",
       "      <td>student english learner work english second th...</td>\n",
       "      <td>limit languag limit worldludwig wittgenstein e...</td>\n",
       "      <td>student need opportun practic begin read skill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p258326</td>\n",
       "      <td>1</td>\n",
       "      <td>want projector hungri learner</td>\n",
       "      <td>student arriv school eager learn polit gener s...</td>\n",
       "      <td>projector need school crucial academ improv st...</td>\n",
       "      <td>student need projector help view educ program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p182444</td>\n",
       "      <td>0</td>\n",
       "      <td>soccer equip awesom middl school student</td>\n",
       "      <td>true champion arent alway one win gut mia hamm...</td>\n",
       "      <td>student campu come school know face uphil batt...</td>\n",
       "      <td>student need shine guard athlet sock soccer ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p246581</td>\n",
       "      <td>1</td>\n",
       "      <td>techi kindergarten</td>\n",
       "      <td>work uniqu school fill esl english second lang...</td>\n",
       "      <td>student live high poverti condit limit access ...</td>\n",
       "      <td>student need engag read math way inspir mini ipad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p104768</td>\n",
       "      <td>1</td>\n",
       "      <td>interact math tool</td>\n",
       "      <td>second grade classroom next year made around 2...</td>\n",
       "      <td>mani student math subject pertain life subject...</td>\n",
       "      <td>student need hand practic mathemat fun person ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  project_is_approved                         project_title_cln  \\\n",
       "0  p253737                    0         educ support english learner home   \n",
       "1  p258326                    1             want projector hungri learner   \n",
       "2  p182444                    0  soccer equip awesom middl school student   \n",
       "3  p246581                    1                        techi kindergarten   \n",
       "4  p104768                    1                        interact math tool   \n",
       "\n",
       "                                     proj_essay1_cln  \\\n",
       "0  student english learner work english second th...   \n",
       "1  student arriv school eager learn polit gener s...   \n",
       "2  true champion arent alway one win gut mia hamm...   \n",
       "3  work uniqu school fill esl english second lang...   \n",
       "4  second grade classroom next year made around 2...   \n",
       "\n",
       "                                     proj_essay2_cln  \\\n",
       "0  limit languag limit worldludwig wittgenstein e...   \n",
       "1  projector need school crucial academ improv st...   \n",
       "2  student campu come school know face uphil batt...   \n",
       "3  student live high poverti condit limit access ...   \n",
       "4  mani student math subject pertain life subject...   \n",
       "\n",
       "                        project_resource_summary_cln  \n",
       "0  student need opportun practic begin read skill...  \n",
       "1      student need projector help view educ program  \n",
       "2  student need shine guard athlet sock soccer ba...  \n",
       "3  student need engag read math way inspir mini ipad  \n",
       "4  student need hand practic mathemat fun person ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp_text = df_nlp[['id', 'project_is_approved', 'project_title_cln', 'proj_essay1_cln', \n",
    "                      'proj_essay2_cln', 'project_resource_summary_cln']].copy()\n",
    "df_nlp_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d20d830e-6c98-490b-9e4a-a1fd477d0bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                               0\n",
       "project_is_approved              0\n",
       "project_title_cln               44\n",
       "proj_essay1_cln                  0\n",
       "proj_essay2_cln                  0\n",
       "project_resource_summary_cln     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp_text.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e6c5cda-f5a9-4689-93d7-9d1857c99882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                              0\n",
       "project_is_approved             0\n",
       "project_title_cln               0\n",
       "proj_essay1_cln                 0\n",
       "proj_essay2_cln                 0\n",
       "project_resource_summary_cln    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp_text.fillna('', inplace=True)\n",
    "df_nlp_text.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7afce0-14ea-4799-a660-1ba3e8558c86",
   "metadata": {},
   "source": [
    "# **Generating Word2Vec: Vectors for Each word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "663c41a9-aaee-4aab-9896-43c94080f795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'educ support english learner home'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp_text['project_title_cln'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d1f8186-7a75-48db-bb93-572d200a304c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['educ', 'support', 'english', 'learner', 'home']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_preprocess(df_nlp_text['project_title_cln'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c76ce71-cb11-4657-85b6-feb46f2b4e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_gen_story(df, col):\n",
    "    story = []\n",
    "    for lst in df[col].apply(simple_preprocess):\n",
    "        story.append(lst)\n",
    "    \n",
    "    return story\n",
    "\n",
    "def word2vec_train(model, story):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.build_vocab(story)\n",
    "    model.train(story, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(end_time-start_time)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b8eebf9-80a8-47db-bd80-f0269aa7586e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.587568998336792\n",
      "6.398947238922119\n",
      "8.308640003204346\n",
      "1.4444620609283447\n"
     ]
    }
   ],
   "source": [
    "story_proj_title = word2vec_gen_story(df_nlp_text, 'project_title_cln')\n",
    "story_proj_ess1 = word2vec_gen_story(df_nlp_text, 'proj_essay1_cln')\n",
    "story_proj_ess2 = word2vec_gen_story(df_nlp_text, 'proj_essay2_cln')\n",
    "story_proj_res = word2vec_gen_story(df_nlp_text, 'project_resource_summary_cln')\n",
    "\n",
    "\n",
    "word2vec_model1 = gensim.models.Word2Vec(window=5, min_count=2, workers=8, vector_size=100)\n",
    "word2vec_model2 = gensim.models.Word2Vec(window=10, min_count=2, workers=8, vector_size=100)\n",
    "word2vec_model3 = gensim.models.Word2Vec(window=10, min_count=2, workers=8, vector_size=100)\n",
    "word2vec_model4 = gensim.models.Word2Vec(window=10, min_count=2, workers=8, vector_size=100)\n",
    "\n",
    "\n",
    "word2vec_model1 = word2vec_train(word2vec_model1, story_proj_title)\n",
    "word2vec_model2 = word2vec_train(word2vec_model2, story_proj_ess1)\n",
    "word2vec_model3 = word2vec_train(word2vec_model3, story_proj_ess2)\n",
    "word2vec_model4 = word2vec_train(word2vec_model4, story_proj_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f388710-9a67-491d-99a8-580d173ec3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length of proj_title: 6618\n",
      "Vocabulary length of proj_ess1: 17003\n",
      "Vocabulary length of proj_ess2: 20761\n",
      "Vocabulary length of proj_res_sum: 9380\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary length of proj_title:', len(word2vec_model1.wv.index_to_key))\n",
    "print('Vocabulary length of proj_ess1:', len(word2vec_model2.wv.index_to_key))\n",
    "print('Vocabulary length of proj_ess2:', len(word2vec_model3.wv.index_to_key))\n",
    "print('Vocabulary length of proj_res_sum:', len(word2vec_model4.wv.index_to_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b58b473e-9506-410e-a7be-af3e84176cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of word vector of any particular word\n",
    "word2vec_model1.wv['read'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87748ecc-b179-487a-b9e5-44e4c0b4d109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (6618, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learn</th>\n",
       "      <td>0.045290</td>\n",
       "      <td>0.042670</td>\n",
       "      <td>0.166546</td>\n",
       "      <td>-0.000281</td>\n",
       "      <td>0.022548</td>\n",
       "      <td>-0.184124</td>\n",
       "      <td>0.019320</td>\n",
       "      <td>0.198408</td>\n",
       "      <td>-0.166268</td>\n",
       "      <td>-0.036648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082366</td>\n",
       "      <td>-0.062818</td>\n",
       "      <td>0.009860</td>\n",
       "      <td>0.055437</td>\n",
       "      <td>0.181060</td>\n",
       "      <td>0.169323</td>\n",
       "      <td>-0.120646</td>\n",
       "      <td>-0.034877</td>\n",
       "      <td>-0.097515</td>\n",
       "      <td>-0.014989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>read</th>\n",
       "      <td>-0.041323</td>\n",
       "      <td>-0.063651</td>\n",
       "      <td>-0.003682</td>\n",
       "      <td>0.156491</td>\n",
       "      <td>0.086488</td>\n",
       "      <td>-0.139032</td>\n",
       "      <td>0.052133</td>\n",
       "      <td>0.123246</td>\n",
       "      <td>-0.065392</td>\n",
       "      <td>-0.113360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104329</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>-0.078074</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.046128</td>\n",
       "      <td>0.040911</td>\n",
       "      <td>0.142084</td>\n",
       "      <td>-0.002652</td>\n",
       "      <td>-0.204565</td>\n",
       "      <td>0.037798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>-0.144410</td>\n",
       "      <td>0.188490</td>\n",
       "      <td>-0.065017</td>\n",
       "      <td>0.042579</td>\n",
       "      <td>-0.093902</td>\n",
       "      <td>-0.122287</td>\n",
       "      <td>-0.070589</td>\n",
       "      <td>0.051658</td>\n",
       "      <td>-0.097895</td>\n",
       "      <td>-0.220864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034698</td>\n",
       "      <td>0.156480</td>\n",
       "      <td>0.124861</td>\n",
       "      <td>-0.009381</td>\n",
       "      <td>0.118072</td>\n",
       "      <td>0.181038</td>\n",
       "      <td>0.032861</td>\n",
       "      <td>-0.064345</td>\n",
       "      <td>0.061937</td>\n",
       "      <td>-0.075793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>-0.147908</td>\n",
       "      <td>0.187027</td>\n",
       "      <td>0.014285</td>\n",
       "      <td>-0.033588</td>\n",
       "      <td>0.117591</td>\n",
       "      <td>-0.039632</td>\n",
       "      <td>-0.099160</td>\n",
       "      <td>0.126854</td>\n",
       "      <td>-0.098300</td>\n",
       "      <td>-0.160967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128923</td>\n",
       "      <td>-0.035847</td>\n",
       "      <td>0.125920</td>\n",
       "      <td>-0.048118</td>\n",
       "      <td>0.164710</td>\n",
       "      <td>-0.003019</td>\n",
       "      <td>0.187531</td>\n",
       "      <td>-0.026646</td>\n",
       "      <td>0.077263</td>\n",
       "      <td>-0.067336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technolog</th>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.206096</td>\n",
       "      <td>0.023511</td>\n",
       "      <td>-0.121799</td>\n",
       "      <td>0.122854</td>\n",
       "      <td>-0.200058</td>\n",
       "      <td>0.090525</td>\n",
       "      <td>0.078380</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>-0.130649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103929</td>\n",
       "      <td>-0.132253</td>\n",
       "      <td>0.074525</td>\n",
       "      <td>0.103694</td>\n",
       "      <td>0.091108</td>\n",
       "      <td>0.082438</td>\n",
       "      <td>0.032840</td>\n",
       "      <td>0.093863</td>\n",
       "      <td>-0.134933</td>\n",
       "      <td>0.008771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holey</th>\n",
       "      <td>-0.090915</td>\n",
       "      <td>0.181997</td>\n",
       "      <td>0.023367</td>\n",
       "      <td>0.108680</td>\n",
       "      <td>0.010764</td>\n",
       "      <td>-0.188472</td>\n",
       "      <td>0.141062</td>\n",
       "      <td>0.257167</td>\n",
       "      <td>-0.097581</td>\n",
       "      <td>-0.059168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126518</td>\n",
       "      <td>0.050244</td>\n",
       "      <td>-0.024046</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>0.248989</td>\n",
       "      <td>0.078041</td>\n",
       "      <td>0.134878</td>\n",
       "      <td>-0.020182</td>\n",
       "      <td>0.069345</td>\n",
       "      <td>-0.015245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walkamoli</th>\n",
       "      <td>-0.062397</td>\n",
       "      <td>0.203894</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.140174</td>\n",
       "      <td>-0.011977</td>\n",
       "      <td>-0.199298</td>\n",
       "      <td>0.093077</td>\n",
       "      <td>0.229559</td>\n",
       "      <td>-0.038019</td>\n",
       "      <td>-0.088947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113836</td>\n",
       "      <td>-0.006813</td>\n",
       "      <td>0.053529</td>\n",
       "      <td>0.031089</td>\n",
       "      <td>0.223817</td>\n",
       "      <td>0.168760</td>\n",
       "      <td>0.142827</td>\n",
       "      <td>-0.025339</td>\n",
       "      <td>0.036352</td>\n",
       "      <td>-0.101561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muse</th>\n",
       "      <td>-0.101493</td>\n",
       "      <td>0.082529</td>\n",
       "      <td>-0.020541</td>\n",
       "      <td>0.130691</td>\n",
       "      <td>0.017734</td>\n",
       "      <td>-0.167331</td>\n",
       "      <td>0.120347</td>\n",
       "      <td>0.212954</td>\n",
       "      <td>-0.058600</td>\n",
       "      <td>-0.040397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181678</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>-0.004712</td>\n",
       "      <td>0.062024</td>\n",
       "      <td>0.203908</td>\n",
       "      <td>0.089305</td>\n",
       "      <td>0.136044</td>\n",
       "      <td>-0.181744</td>\n",
       "      <td>0.099551</td>\n",
       "      <td>-0.067937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geoboard</th>\n",
       "      <td>0.021209</td>\n",
       "      <td>0.066078</td>\n",
       "      <td>-0.016095</td>\n",
       "      <td>-0.065352</td>\n",
       "      <td>-0.004728</td>\n",
       "      <td>-0.242117</td>\n",
       "      <td>0.073599</td>\n",
       "      <td>0.293602</td>\n",
       "      <td>-0.024526</td>\n",
       "      <td>-0.032971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092540</td>\n",
       "      <td>-0.030949</td>\n",
       "      <td>0.007858</td>\n",
       "      <td>0.011019</td>\n",
       "      <td>0.269781</td>\n",
       "      <td>0.136819</td>\n",
       "      <td>0.166038</td>\n",
       "      <td>-0.188283</td>\n",
       "      <td>0.118046</td>\n",
       "      <td>-0.049586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impression</th>\n",
       "      <td>-0.094423</td>\n",
       "      <td>0.162578</td>\n",
       "      <td>0.073004</td>\n",
       "      <td>0.032879</td>\n",
       "      <td>0.012762</td>\n",
       "      <td>-0.178356</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.222933</td>\n",
       "      <td>-0.076471</td>\n",
       "      <td>0.014749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126506</td>\n",
       "      <td>0.055523</td>\n",
       "      <td>-0.006552</td>\n",
       "      <td>-0.051594</td>\n",
       "      <td>0.292684</td>\n",
       "      <td>0.126583</td>\n",
       "      <td>0.162352</td>\n",
       "      <td>-0.146907</td>\n",
       "      <td>0.065799</td>\n",
       "      <td>-0.063195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6618 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4         5   \\\n",
       "learn       0.045290  0.042670  0.166546 -0.000281  0.022548 -0.184124   \n",
       "read       -0.041323 -0.063651 -0.003682  0.156491  0.086488 -0.139032   \n",
       "need       -0.144410  0.188490 -0.065017  0.042579 -0.093902 -0.122287   \n",
       "student    -0.147908  0.187027  0.014285 -0.033588  0.117591 -0.039632   \n",
       "technolog   0.005644  0.206096  0.023511 -0.121799  0.122854 -0.200058   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "holey      -0.090915  0.181997  0.023367  0.108680  0.010764 -0.188472   \n",
       "walkamoli  -0.062397  0.203894  0.008008  0.140174 -0.011977 -0.199298   \n",
       "muse       -0.101493  0.082529 -0.020541  0.130691  0.017734 -0.167331   \n",
       "geoboard    0.021209  0.066078 -0.016095 -0.065352 -0.004728 -0.242117   \n",
       "impression -0.094423  0.162578  0.073004  0.032879  0.012762 -0.178356   \n",
       "\n",
       "                  6         7         8         9   ...        90        91  \\\n",
       "learn       0.019320  0.198408 -0.166268 -0.036648  ...  0.082366 -0.062818   \n",
       "read        0.052133  0.123246 -0.065392 -0.113360  ...  0.104329 -0.005957   \n",
       "need       -0.070589  0.051658 -0.097895 -0.220864  ... -0.034698  0.156480   \n",
       "student    -0.099160  0.126854 -0.098300 -0.160967  ... -0.128923 -0.035847   \n",
       "technolog   0.090525  0.078380  0.006332 -0.130649  ...  0.103929 -0.132253   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "holey       0.141062  0.257167 -0.097581 -0.059168  ...  0.126518  0.050244   \n",
       "walkamoli   0.093077  0.229559 -0.038019 -0.088947  ...  0.113836 -0.006813   \n",
       "muse        0.120347  0.212954 -0.058600 -0.040397  ...  0.181678  0.016709   \n",
       "geoboard    0.073599  0.293602 -0.024526 -0.032971  ...  0.092540 -0.030949   \n",
       "impression  0.136002  0.222933 -0.076471  0.014749  ...  0.126506  0.055523   \n",
       "\n",
       "                  92        93        94        95        96        97  \\\n",
       "learn       0.009860  0.055437  0.181060  0.169323 -0.120646 -0.034877   \n",
       "read       -0.078074  0.057200  0.046128  0.040911  0.142084 -0.002652   \n",
       "need        0.124861 -0.009381  0.118072  0.181038  0.032861 -0.064345   \n",
       "student     0.125920 -0.048118  0.164710 -0.003019  0.187531 -0.026646   \n",
       "technolog   0.074525  0.103694  0.091108  0.082438  0.032840  0.093863   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "holey      -0.024046 -0.000385  0.248989  0.078041  0.134878 -0.020182   \n",
       "walkamoli   0.053529  0.031089  0.223817  0.168760  0.142827 -0.025339   \n",
       "muse       -0.004712  0.062024  0.203908  0.089305  0.136044 -0.181744   \n",
       "geoboard    0.007858  0.011019  0.269781  0.136819  0.166038 -0.188283   \n",
       "impression -0.006552 -0.051594  0.292684  0.126583  0.162352 -0.146907   \n",
       "\n",
       "                  98        99  \n",
       "learn      -0.097515 -0.014989  \n",
       "read       -0.204565  0.037798  \n",
       "need        0.061937 -0.075793  \n",
       "student     0.077263 -0.067336  \n",
       "technolog  -0.134933  0.008771  \n",
       "...              ...       ...  \n",
       "holey       0.069345 -0.015245  \n",
       "walkamoli   0.036352 -0.101561  \n",
       "muse        0.099551 -0.067937  \n",
       "geoboard    0.118046 -0.049586  \n",
       "impression  0.065799 -0.063195  \n",
       "\n",
       "[6618 rows x 100 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the vector representation of the vocabulary of any textual feature\n",
    "view_model = word2vec_model1\n",
    "df_vocab_view_model = pd.DataFrame(view_model.wv.get_normed_vectors(), index=view_model.wv.index_to_key)\n",
    "print('Shape:', df_vocab_view_model. shape)\n",
    "df_vocab_view_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed0d2077-9e3c-4e1b-a740-88a13b62d14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fluenci', 0.7221347689628601),\n",
       " ('comprehens', 0.7146868109703064),\n",
       " ('nonfict', 0.7111363410949707),\n",
       " ('aloud', 0.6790169477462769),\n",
       " ('foster', 0.6778611540794373),\n",
       " ('instil', 0.6752875447273254),\n",
       " ('rekindl', 0.6741672158241272),\n",
       " ('selfselect', 0.6712664365768433),\n",
       " ('nook', 0.6699384450912476),\n",
       " ('cd', 0.6659601926803589)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model1.wv.most_similar('read')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e2db9b-b61f-4b35-afdd-c502aee96b06",
   "metadata": {},
   "source": [
    "# **Generating Average Word2Vec: Vectors for each document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b828a7b3-e815-42af-b72e-10dcd9cc5546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move 2nd grade 3rd grade begin next school year take current student move teach inclus classroom includ student adhd sld well autist student student work hard achiev goal matter struggl may school teach hous great deal autist student well ell student student love read work challeng also love move around work better abl move room differ area rather usual set\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.11494264,  0.3799368 , -0.00770212, -0.2100841 , -0.6650044 ,\n",
       "       -0.48449647, -0.34660646,  0.49904191,  0.17497565,  0.09198917,\n",
       "       -0.52872837,  1.0793037 , -0.36428213, -1.1069055 , -0.1424415 ,\n",
       "        1.0061094 , -0.47118583,  0.9869686 , -0.23240829, -0.53228736,\n",
       "       -0.23206952, -0.17435393, -0.00267876,  0.10386855,  0.24099359,\n",
       "        0.26176694, -0.32554257, -0.23715177,  0.8111061 ,  0.25708747,\n",
       "       -0.42449963,  0.70317143, -0.09232473,  0.70687   ,  0.41302806,\n",
       "       -1.0874805 , -0.24322167,  0.24349521, -0.30441013,  0.13283093,\n",
       "        0.38327554,  0.09884408,  0.22680204,  0.37058067,  0.62848693,\n",
       "       -0.79873216,  0.5925496 ,  0.2071998 , -0.41693527, -0.24388504,\n",
       "       -1.2168086 ,  0.74037486,  0.07998767, -0.03032509, -0.34628862,\n",
       "        0.49609444, -0.41647214,  0.04860004,  0.09098256,  0.19382945,\n",
       "       -0.12265771, -0.10411967, -0.03322358,  0.72808766,  0.7307038 ,\n",
       "       -0.38975522,  0.3463566 ,  0.26389763,  0.6933319 , -0.28890637,\n",
       "        0.38917896,  0.44414568, -0.5204689 ,  0.25258556, -0.696705  ,\n",
       "       -0.86831445, -0.34193113, -0.34406152, -0.3642344 ,  0.03357627,\n",
       "        0.26738128,  0.29040748,  0.6263565 ,  0.01464636,  0.15256627,\n",
       "       -0.47573978, -0.38202062,  0.05601525, -1.0671139 , -0.6144996 ,\n",
       "        0.39686722,  0.79841226,  0.24422589, -0.19978616, -0.9583785 ,\n",
       "       -0.14554502,  0.4257202 , -0.22873837,  0.20840326,  0.57231766],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word2vec_gen_docvec(text, model):\n",
    "    \n",
    "    # wordvec_dim = model.wv[model.wv.index_to_key[0]].shape[0]\n",
    "    # avg_vec = np.zeros(wordvec_dim)\n",
    "    # num_of_wrds = 0\n",
    "    # # print(wordvec_dim, num_of_wrds)\n",
    "    # word_lst = simple_preprocess(text)\n",
    "    # for wrd in word_lst:\n",
    "    #     if wrd in model.wv.key_to_index:\n",
    "    #         num_of_wrds += 1\n",
    "    #         avg_vec += model.wv[wrd]\n",
    "    # avg_vec = avg_vec/num_of_wrds\n",
    "    \n",
    "    \n",
    "    wordvec_dim = model.wv[model.wv.index_to_key[0]].shape[0]\n",
    "    avg_vec = np.zeros(wordvec_dim)\n",
    "    # This check is to account for words for whom vector is not created (min_count=2)\n",
    "    doc = [wrd for wrd in simple_preprocess(text) if wrd in model.wv.key_to_index]\n",
    "    # print(doc)\n",
    "    if len(doc)>0:\n",
    "        avg_vec = np.mean(model.wv[doc], axis=0)\n",
    "    return avg_vec\n",
    "\n",
    "\n",
    "test_doc = df_nlp_text['proj_essay1_cln'].iloc[5]\n",
    "print(test_doc)\n",
    "print('-'*80)\n",
    "word2vec_gen_docvec(test_doc, word2vec_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b400729-b53c-42ae-b83f-b189d4bfb3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5562009811401367\n",
      "9.7330482006073\n",
      "11.846950054168701\n",
      "2.773733139038086\n",
      "(109245, 100)\n",
      "(109245, 100)\n",
      "(109245, 100)\n",
      "(109245, 100)\n"
     ]
    }
   ],
   "source": [
    "def word2vec_gen_docvec_arr(df, col, model):\n",
    "    arr = []\n",
    "    start_time=time.time()\n",
    "    for doc in df[col].values:\n",
    "        arr.append(word2vec_gen_docvec(doc, model))\n",
    "    end_time=time.time()\n",
    "    print(end_time-start_time)\n",
    "                            \n",
    "    return np.array(arr)\n",
    "\n",
    "docvec_arr_proj_title = word2vec_gen_docvec_arr(df_nlp_text, 'project_title_cln', word2vec_model1)\n",
    "docvec_arr_proj_ess1 = word2vec_gen_docvec_arr(df_nlp_text, 'proj_essay1_cln', word2vec_model2)\n",
    "docvec_arr_proj_ess2 = word2vec_gen_docvec_arr(df_nlp_text, 'proj_essay2_cln', word2vec_model3)\n",
    "docvec_arr_proj_res = word2vec_gen_docvec_arr(df_nlp_text, 'project_resource_summary_cln', word2vec_model4)\n",
    "\n",
    "print(docvec_arr_proj_title.shape)\n",
    "print(docvec_arr_proj_ess1.shape)\n",
    "print(docvec_arr_proj_ess2.shape)\n",
    "print(docvec_arr_proj_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0af6d7f5-65e9-4a9b-bcca-69941055d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_gen_docvec_df(arr, prefix, flag=0):\n",
    "    df = pd.DataFrame(arr)\n",
    "    df.columns = [f'w2v_{prefix}_{col}' for col in df.columns]\n",
    "    if flag==1:\n",
    "        df[f'{prefix}_skew'] = skew(arr, axis=1)\n",
    "        df[f'{prefix}_kurt'] = kurtosis(arr, axis=1)\n",
    "                            \n",
    "    return df\n",
    "\n",
    "\n",
    "df_arr_proj_title = word2vec_gen_docvec_df(docvec_arr_proj_title, 'title', 0)\n",
    "df_arr_proj_ess1 = word2vec_gen_docvec_df(docvec_arr_proj_ess1, 'ess1', 0)\n",
    "df_arr_proj_ess2 = word2vec_gen_docvec_df(docvec_arr_proj_ess2, 'ess2', 0)\n",
    "df_arr_proj_res = word2vec_gen_docvec_df(docvec_arr_proj_res, 'res_sum', 0)\n",
    "\n",
    "\n",
    "df_arr_proj_title_sk = word2vec_gen_docvec_df(docvec_arr_proj_title, 'title', 1)\n",
    "df_arr_proj_ess1_sk = word2vec_gen_docvec_df(docvec_arr_proj_ess1, 'ess1', 1)\n",
    "df_arr_proj_ess2_sk = word2vec_gen_docvec_df(docvec_arr_proj_ess2, 'ess2', 1)\n",
    "df_arr_proj_res_sk = word2vec_gen_docvec_df(docvec_arr_proj_res, 'res_sum', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a944a45b-4015-4585-bacd-6832cb6fd1e4",
   "metadata": {},
   "source": [
    "# **Stacking the document vectors together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d585d835-70f4-412d-a9d7-c55c2180ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.hstack((docvec_arr_proj_title, docvec_arr_proj_ess1, docvec_arr_proj_ess2, docvec_arr_proj_res)).shape)\n",
    "# pd.DataFrame(np.hstack((docvec_arr_proj_title, docvec_arr_proj_ess1, docvec_arr_proj_ess2, docvec_arr_proj_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c779eee9-6ebc-447c-af5f-1f5beb40d5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109245, 400)\n",
      "(109245, 408)\n"
     ]
    }
   ],
   "source": [
    "def merge_df_arr(df1, df2, df3, df4):\n",
    "    df_int1 = pd.merge(df1, df2, left_index=True, right_index=True)\n",
    "    df_int2 = pd.merge(df_int1, df3, left_index=True, right_index=True)\n",
    "    df_merged = pd.merge(df_int2, df4, left_index=True, right_index=True)\n",
    "    return df_merged\n",
    "\n",
    "df_arr_merged_text_feat = merge_df_arr(df_arr_proj_title, df_arr_proj_ess1, df_arr_proj_ess2, df_arr_proj_res)\n",
    "print(df_arr_merged_text_feat.shape)\n",
    "\n",
    "df_arr_merged_text_feat_sk = merge_df_arr(df_arr_proj_title_sk, df_arr_proj_ess1_sk, df_arr_proj_ess2_sk, df_arr_proj_res_sk)\n",
    "print(df_arr_merged_text_feat_sk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f46e608c-b9e1-4477-8685-6022eb4efa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values in df_arr_merged_text_feat\n",
    "df_arr_merged_text_feat.isna().sum().loc[df_arr_merged_text_feat.isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e305fda-6e8c-4a4f-b30a-e8c2c2fcca24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_skew    166\n",
      "title_kurt    166\n",
      "dtype: int64\n",
      "--------------------------------------------------\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check missing values in df_arr_merged_text_feat_sk\n",
    "print(df_arr_merged_text_feat_sk.isna().sum().loc[df_arr_merged_text_feat_sk.isna().sum()>0])\n",
    "print('-'*50)\n",
    "df_arr_merged_text_feat_sk.fillna(0, inplace=True)\n",
    "print(df_arr_merged_text_feat_sk.isna().sum().loc[df_arr_merged_text_feat_sk.isna().sum()>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb1219-bf8a-443d-bec5-db6797125f9a",
   "metadata": {},
   "source": [
    "# **Compiling and Saving Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d41560bf-b4e5-408e-9d64-1c53587174ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109245, 401)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w2v_title_0</th>\n",
       "      <th>w2v_title_1</th>\n",
       "      <th>w2v_title_2</th>\n",
       "      <th>w2v_title_3</th>\n",
       "      <th>w2v_title_4</th>\n",
       "      <th>w2v_title_5</th>\n",
       "      <th>w2v_title_6</th>\n",
       "      <th>w2v_title_7</th>\n",
       "      <th>w2v_title_8</th>\n",
       "      <th>w2v_title_9</th>\n",
       "      <th>...</th>\n",
       "      <th>w2v_res_sum_91</th>\n",
       "      <th>w2v_res_sum_92</th>\n",
       "      <th>w2v_res_sum_93</th>\n",
       "      <th>w2v_res_sum_94</th>\n",
       "      <th>w2v_res_sum_95</th>\n",
       "      <th>w2v_res_sum_96</th>\n",
       "      <th>w2v_res_sum_97</th>\n",
       "      <th>w2v_res_sum_98</th>\n",
       "      <th>w2v_res_sum_99</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.095794</td>\n",
       "      <td>0.821023</td>\n",
       "      <td>0.165957</td>\n",
       "      <td>-0.232400</td>\n",
       "      <td>-0.160335</td>\n",
       "      <td>-0.846026</td>\n",
       "      <td>-0.254201</td>\n",
       "      <td>0.670786</td>\n",
       "      <td>-0.614181</td>\n",
       "      <td>-0.655630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053628</td>\n",
       "      <td>0.299027</td>\n",
       "      <td>0.331118</td>\n",
       "      <td>-0.570799</td>\n",
       "      <td>0.159491</td>\n",
       "      <td>0.692381</td>\n",
       "      <td>0.202680</td>\n",
       "      <td>0.707922</td>\n",
       "      <td>1.350626</td>\n",
       "      <td>p253737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.052652</td>\n",
       "      <td>0.569649</td>\n",
       "      <td>-0.085386</td>\n",
       "      <td>0.076098</td>\n",
       "      <td>-0.024387</td>\n",
       "      <td>-0.669934</td>\n",
       "      <td>-0.059968</td>\n",
       "      <td>0.702918</td>\n",
       "      <td>-0.503515</td>\n",
       "      <td>-0.439409</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057715</td>\n",
       "      <td>0.101178</td>\n",
       "      <td>0.147903</td>\n",
       "      <td>-0.008279</td>\n",
       "      <td>0.291279</td>\n",
       "      <td>0.321519</td>\n",
       "      <td>-0.248444</td>\n",
       "      <td>0.665515</td>\n",
       "      <td>1.039950</td>\n",
       "      <td>p258326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.327893</td>\n",
       "      <td>0.970274</td>\n",
       "      <td>-0.169125</td>\n",
       "      <td>0.468727</td>\n",
       "      <td>-0.333180</td>\n",
       "      <td>-0.553257</td>\n",
       "      <td>0.178566</td>\n",
       "      <td>0.780312</td>\n",
       "      <td>-0.051462</td>\n",
       "      <td>-0.172929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651809</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.808386</td>\n",
       "      <td>1.211543</td>\n",
       "      <td>0.647845</td>\n",
       "      <td>-0.257385</td>\n",
       "      <td>-0.555258</td>\n",
       "      <td>0.343186</td>\n",
       "      <td>0.540692</td>\n",
       "      <td>p182444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   w2v_title_0  w2v_title_1  w2v_title_2  w2v_title_3  w2v_title_4  \\\n",
       "0    -0.095794     0.821023     0.165957    -0.232400    -0.160335   \n",
       "1    -0.052652     0.569649    -0.085386     0.076098    -0.024387   \n",
       "2    -0.327893     0.970274    -0.169125     0.468727    -0.333180   \n",
       "\n",
       "   w2v_title_5  w2v_title_6  w2v_title_7  w2v_title_8  w2v_title_9  ...  \\\n",
       "0    -0.846026    -0.254201     0.670786    -0.614181    -0.655630  ...   \n",
       "1    -0.669934    -0.059968     0.702918    -0.503515    -0.439409  ...   \n",
       "2    -0.553257     0.178566     0.780312    -0.051462    -0.172929  ...   \n",
       "\n",
       "   w2v_res_sum_91  w2v_res_sum_92  w2v_res_sum_93  w2v_res_sum_94  \\\n",
       "0       -0.053628        0.299027        0.331118       -0.570799   \n",
       "1       -0.057715        0.101178        0.147903       -0.008279   \n",
       "2        0.651809        0.007812        0.808386        1.211543   \n",
       "\n",
       "   w2v_res_sum_95  w2v_res_sum_96  w2v_res_sum_97  w2v_res_sum_98  \\\n",
       "0        0.159491        0.692381        0.202680        0.707922   \n",
       "1        0.291279        0.321519       -0.248444        0.665515   \n",
       "2        0.647845       -0.257385       -0.555258        0.343186   \n",
       "\n",
       "   w2v_res_sum_99       id  \n",
       "0        1.350626  p253737  \n",
       "1        1.039950  p258326  \n",
       "2        0.540692  p182444  \n",
       "\n",
       "[3 rows x 401 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp_wordvec = pd.merge(df_arr_merged_text_feat, df_nlp_text['id'], left_index=True, right_index=True)\n",
    "print(df_nlp_wordvec.shape)\n",
    "print('-'*50)\n",
    "df_nlp_wordvec.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fe3a2a5-1bec-4d6a-a13a-a6bed979a214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109245, 409)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w2v_title_0</th>\n",
       "      <th>w2v_title_1</th>\n",
       "      <th>w2v_title_2</th>\n",
       "      <th>w2v_title_3</th>\n",
       "      <th>w2v_title_4</th>\n",
       "      <th>w2v_title_5</th>\n",
       "      <th>w2v_title_6</th>\n",
       "      <th>w2v_title_7</th>\n",
       "      <th>w2v_title_8</th>\n",
       "      <th>w2v_title_9</th>\n",
       "      <th>...</th>\n",
       "      <th>w2v_res_sum_93</th>\n",
       "      <th>w2v_res_sum_94</th>\n",
       "      <th>w2v_res_sum_95</th>\n",
       "      <th>w2v_res_sum_96</th>\n",
       "      <th>w2v_res_sum_97</th>\n",
       "      <th>w2v_res_sum_98</th>\n",
       "      <th>w2v_res_sum_99</th>\n",
       "      <th>res_sum_skew</th>\n",
       "      <th>res_sum_kurt</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.095794</td>\n",
       "      <td>0.821023</td>\n",
       "      <td>0.165957</td>\n",
       "      <td>-0.232400</td>\n",
       "      <td>-0.160335</td>\n",
       "      <td>-0.846026</td>\n",
       "      <td>-0.254201</td>\n",
       "      <td>0.670786</td>\n",
       "      <td>-0.614181</td>\n",
       "      <td>-0.655630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331118</td>\n",
       "      <td>-0.570799</td>\n",
       "      <td>0.159491</td>\n",
       "      <td>0.692381</td>\n",
       "      <td>0.202680</td>\n",
       "      <td>0.707922</td>\n",
       "      <td>1.350626</td>\n",
       "      <td>0.101466</td>\n",
       "      <td>-0.567463</td>\n",
       "      <td>p253737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.052652</td>\n",
       "      <td>0.569649</td>\n",
       "      <td>-0.085386</td>\n",
       "      <td>0.076098</td>\n",
       "      <td>-0.024387</td>\n",
       "      <td>-0.669934</td>\n",
       "      <td>-0.059968</td>\n",
       "      <td>0.702918</td>\n",
       "      <td>-0.503515</td>\n",
       "      <td>-0.439409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147903</td>\n",
       "      <td>-0.008279</td>\n",
       "      <td>0.291279</td>\n",
       "      <td>0.321519</td>\n",
       "      <td>-0.248444</td>\n",
       "      <td>0.665515</td>\n",
       "      <td>1.039950</td>\n",
       "      <td>0.161820</td>\n",
       "      <td>0.685040</td>\n",
       "      <td>p258326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.327893</td>\n",
       "      <td>0.970274</td>\n",
       "      <td>-0.169125</td>\n",
       "      <td>0.468727</td>\n",
       "      <td>-0.333180</td>\n",
       "      <td>-0.553257</td>\n",
       "      <td>0.178566</td>\n",
       "      <td>0.780312</td>\n",
       "      <td>-0.051462</td>\n",
       "      <td>-0.172929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808386</td>\n",
       "      <td>1.211543</td>\n",
       "      <td>0.647845</td>\n",
       "      <td>-0.257385</td>\n",
       "      <td>-0.555258</td>\n",
       "      <td>0.343186</td>\n",
       "      <td>0.540692</td>\n",
       "      <td>-0.128192</td>\n",
       "      <td>0.055842</td>\n",
       "      <td>p182444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 409 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   w2v_title_0  w2v_title_1  w2v_title_2  w2v_title_3  w2v_title_4  \\\n",
       "0    -0.095794     0.821023     0.165957    -0.232400    -0.160335   \n",
       "1    -0.052652     0.569649    -0.085386     0.076098    -0.024387   \n",
       "2    -0.327893     0.970274    -0.169125     0.468727    -0.333180   \n",
       "\n",
       "   w2v_title_5  w2v_title_6  w2v_title_7  w2v_title_8  w2v_title_9  ...  \\\n",
       "0    -0.846026    -0.254201     0.670786    -0.614181    -0.655630  ...   \n",
       "1    -0.669934    -0.059968     0.702918    -0.503515    -0.439409  ...   \n",
       "2    -0.553257     0.178566     0.780312    -0.051462    -0.172929  ...   \n",
       "\n",
       "   w2v_res_sum_93  w2v_res_sum_94  w2v_res_sum_95  w2v_res_sum_96  \\\n",
       "0        0.331118       -0.570799        0.159491        0.692381   \n",
       "1        0.147903       -0.008279        0.291279        0.321519   \n",
       "2        0.808386        1.211543        0.647845       -0.257385   \n",
       "\n",
       "   w2v_res_sum_97  w2v_res_sum_98  w2v_res_sum_99  res_sum_skew  res_sum_kurt  \\\n",
       "0        0.202680        0.707922        1.350626      0.101466     -0.567463   \n",
       "1       -0.248444        0.665515        1.039950      0.161820      0.685040   \n",
       "2       -0.555258        0.343186        0.540692     -0.128192      0.055842   \n",
       "\n",
       "        id  \n",
       "0  p253737  \n",
       "1  p258326  \n",
       "2  p182444  \n",
       "\n",
       "[3 rows x 409 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp_wordvec_skew_kurt = pd.merge(df_arr_merged_text_feat_sk, df_nlp_text['id'], left_index=True, right_index=True)\n",
    "print(df_nlp_wordvec_skew_kurt.shape)\n",
    "print('-'*50)\n",
    "df_nlp_wordvec_skew_kurt.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "044a45d4-0cce-43ef-becf-e36749fc68ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_nlp_wordvec.to_csv(path_or_buf='./data/nlp_features/df_nlp_wordvec.csv', sep=',', index=False)\n",
    "# df_nlp_wordvec_skew_kurt.to_csv(path_or_buf='./data/nlp_features/df_nlp_wordvec_skew_kurt.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5084d2f-6b3d-43c6-99a3-b6d35902bad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac95e36c-32a2-4740-91e1-6530e130e8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4283c13-e97d-4b46-962a-1a6b455b579c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef1ce4e-dc25-40e9-bf7d-130814d1e7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
